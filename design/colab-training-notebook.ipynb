{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0001",
   "metadata": {},
   "source": [
    "# YOLOv8n Resistor Detector — Colab Training Notebook\n",
    "\n",
    "**Project:** VivaLaResistance  \n",
    "**Dataset:** [isha-74mjj/yolov5-u3oks v3](https://universe.roboflow.com/isha-74mjj/yolov5-u3oks/dataset/3) on Roboflow (4,422 images, CC-BY 4.0)  \n",
    "**Target:** YOLOv8n → ONNX opset 17, fixed batch=1, 640px input  \n",
    "**Runtime:** Google Colab with T4 GPU (Runtime → Change runtime type → GPU)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0002",
   "metadata": {},
   "source": [
    "## Section 1: Setup\n",
    "\n",
    "Install `ultralytics` (YOLOv8) and `roboflow` (dataset download). This takes ~60 seconds on a fresh Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics roboflow\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0004",
   "metadata": {},
   "source": [
    "## Section 2: Download Dataset from Roboflow\n",
    "\n",
    "You need a free Roboflow account. Get your API key at [roboflow.com](https://roboflow.com) → Settings → API.  \n",
    "Replace `\"YOUR_ROBOFLOW_API_KEY\"` below before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"YOUR_ROBOFLOW_API_KEY\")  # get free key at roboflow.com\n",
    "project = rf.workspace(\"isha-74mjj\").project(\"yolov5-u3oks\")\n",
    "version = project.version(3)  # confirmed v3 — https://universe.roboflow.com/isha-74mjj/yolov5-u3oks/dataset/3\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0006",
   "metadata": {},
   "source": [
    "## Section 3: Train YOLOv8n\n",
    "\n",
    "Trains YOLOv8-nano on the resistor dataset with early stopping (patience=10).  \n",
    "**With a T4 GPU on Colab, 50 epochs on 4,422 images takes ~25–40 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model.train(\n",
    "    data=f\"{dataset.location}/data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,          # GPU (Colab T4)\n",
    "    patience=10,       # early stopping\n",
    "    project=\"resistor-detector\",\n",
    "    name=\"yolov8n-run1\",\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0008",
   "metadata": {},
   "source": [
    "## Section 4: Evaluate\n",
    "\n",
    "Run validation on the held-out val set to check model quality before exporting.\n",
    "\n",
    "**Target: mAP50 > 0.70 before exporting. If below 0.65, increase epochs to 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()\n",
    "print(f\"mAP50:    {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0010",
   "metadata": {},
   "source": [
    "## Section 5: Export to ONNX\n",
    "\n",
    "Export the best checkpoint to ONNX format with fixed batch size 1 (required for mobile inference via `Microsoft.ML.OnnxRuntime`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\n",
    "    format=\"onnx\",\n",
    "    imgsz=640,\n",
    "    simplify=True,\n",
    "    opset=17,\n",
    "    dynamic=False      # fixed batch=1 for mobile\n",
    ")\n",
    "# Output: resistor-detector/yolov8n-run1/weights/best.onnx\n",
    "print(\"Export complete. Download best.onnx from the Files panel →\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0012",
   "metadata": {},
   "source": [
    "## Section 6: Validate the Exported Model\n",
    "\n",
    "1. Download `best.onnx` from the Colab Files panel (folder icon on the left sidebar)\n",
    "2. Open [https://netron.app](https://netron.app) and drag the file in\n",
    "3. Verify:\n",
    "   - **Input:** `float32 [1, 3, 640, 640]`\n",
    "   - **Output:** `float32 [1, 5, 8400]`  \n",
    "     *(YOLOv8 detection head — 4 bbox coords + 80 COCO classes, but we have 1 class so it will be `[1, 5, 8400]`)*\n",
    "4. Rename file to `resistor-localization.onnx`\n",
    "5. Place in: `src/VivaLaResistance/Resources/Raw/resistor-localization.onnx`\n",
    "6. Set build action to `MauiAsset` in the `.csproj`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0013",
   "metadata": {},
   "source": [
    "## Section 7: C# Integration Notes\n",
    "\n",
    "### ONNX Output Format\n",
    "\n",
    "YOLOv8 exports a single output tensor shaped `[1, 5, 8400]` where:\n",
    "- **8400** = number of candidate anchor boxes (decoded, not raw anchors)\n",
    "- **5 values per box** = `[cx, cy, w, h, conf]`\n",
    "  - `cx`, `cy` — box centre, normalised to `[0, 1]` relative to 640×640 input\n",
    "  - `w`, `h` — box dimensions, normalised to `[0, 1]`\n",
    "  - `conf` — objectness confidence score `[0, 1]`\n",
    "\n",
    "### Post-Processing (NMS)\n",
    "\n",
    "ONNX Runtime does **not** apply NMS internally. You must apply it in C# after inference:\n",
    "- **Confidence threshold:** 0.25 (discard boxes below this)\n",
    "- **IoU threshold:** 0.45 (suppress overlapping boxes in NMS)\n",
    "\n",
    "### Input Preprocessing\n",
    "\n",
    "The MAUI camera frame arrives as **BGRA8888** byte[]. Convert to the model's expected format:\n",
    "\n",
    "1. **Resize** to 640×640 (letterbox if aspect ratio differs, pad with grey `(114,114,114)`)\n",
    "2. **Reorder channels:** BGRA → RGB (drop alpha, swap B and R)\n",
    "3. **Normalise:** divide each pixel value by 255.0 → `float32` in `[0, 1]`\n",
    "4. **CHW layout:** output a flat `float32[3 × 640 × 640]` array in planar order (all R, then all G, then all B)\n",
    "\n",
    "### C# Stub\n",
    "\n",
    "`OnnxResistorLocalizationService.cs` in `src/VivaLaResistance.Services/` is scaffolded and compiles against `Microsoft.ML.OnnxRuntime 1.20.1`. Once `resistor-localization.onnx` is placed in `Resources/Raw/` with `MauiAsset` build action, implement:\n",
    "- `InitializeAsync` — load model from stream via `InferenceSession`\n",
    "- `InferAsync` — preprocess BGRA8888 frame, run session, decode `[1, 5, 8400]` output, apply NMS, return `IReadOnlyList<ResistorBoundingBox>`\n",
    "\n",
    "Bounding box coordinates returned to Shuri's overlay renderer are **normalised `[0, 1]`** as defined in `ResistorBoundingBox` (Core.Models)."
   ]
  }
 ]
}